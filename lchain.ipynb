{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      ""
      "Generated Response: Why do ducks have feathers?\n",
      "\n",
      "To cover their butt quacks!\n",
      "{'token_usage': {'completion_tokens': 13, 'prompt_tokens': 22, 'total_tokens': 35, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo', 'system_fingerprint': 'fp_83975a045a'}\n",
      "Here are some examples of text categorized with sentiment analysis:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    \"text\": \"I absolutely love this product! It works great and exceeded my expectations.\",\n",
      "    \"category\": \"Product Review\",\n",
      "    \"sentiment\": \"Positive\"\n",
      "\n",
      "\n",
      "\n",
      "    \"text\": \"The customer service was terrible, and I am very disappointed with the response time.\",\n",
      "    \"category\": \"Customer Service\",\n",
      "    \"sentiment\": \"Negative\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Analyze the following text and provide the category and sentiment:\n",
      "The packaging was damaged, but the product inside is fantastic.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "is_environment_loaded = load_dotenv(find_dotenv())\n",
    "print(is_environment_loaded)\n",
    "\n",
    "api_key  = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# Initialize ChatOpenAI with the GPT-4-turbo model\n",
    "llm = ChatOpenAI(model_name=\"gpt-4-turbo\")\n",
    "\n",
    "# Generate a conversational response using a HumanMessage\n",
    "response = llm.generate([[HumanMessage(content=\"Tell me a funny drunk joke as a friend would, without any code.\")]])\n",
    "\n",
    "# Print the generated joke\n",
    "print(\"Generated Response:\", response.generations[0][0].text)\n",
    "print(response.llm_output)\n",
    "\n",
    "\n",
    "#Prompt Templates\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "TEMPLATE = \"\"\"\n",
    "Write a {style} paragraph about {subject}\n",
    "\"\"\"\n",
    "\n",
    "#template from constructor\n",
    "template = PromptTemplate(\n",
    "    input_variables=[\"subject\", \"style\"],\n",
    "    template=TEMPLATE\n",
    ")\n",
    "\n",
    "#template from factory method\n",
    "exteral_template = PromptTemplate.from_template(template=TEMPLATE)\n",
    "\n",
    "exteral_template.format(style=\"information\", subject= \"machine learning\")\n",
    "\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "\n",
    "# Define some few-shot examples for sentiment analysis\n",
    "examples = [\n",
    "    {\n",
    "        \"text\": \"I absolutely love this product! It works great and exceeded my expectations.\",\n",
    "        \"category\": \"Product Review\",\n",
    "        \"sentiment\": \"Positive\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"The customer service was terrible, and I am very disappointed with the response time.\",\n",
    "        \"category\": \"Customer Service\",\n",
    "        \"sentiment\": \"Negative\"\n",
    "    },\n",
    "]\n",
    "\n",
    "# Create a PromptTemplate for formatting each example\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"category\", \"sentiment\"],\n",
    "    template=\"\"\"\n",
    "    \"text\": \"{text}\",\n",
    "    \"category\": \"{category}\",\n",
    "    \"sentiment\": \"{sentiment}\"\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Create the FewShotPromptTemplate\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    example_separator=\"\\n\\n\",  # Separator between examples\n",
    "    prefix=\"Here are some examples of text categorized with sentiment analysis:\\n\\n\",  # Optional prefix\n",
    "    suffix=\"\\n\\nAnalyze the following text and provide the category and sentiment:\\n{text}\",  # Optional suffix\n",
    "    input_variables=[\"text\"]  # Input variable for the final prompt\n",
    ")\n",
    "\n",
    "# Format the prompt with a new text to analyze\n",
    "formatted_prompt = few_shot_prompt.format(\n",
    "    text=\"The packaging was damaged, but the product inside is fantastic.\"\n",
    ")\n",
    "\n",
    "print(formatted_prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Reasoning\": \"The text indicates a moderate satisfaction with the food described as 'decent' and a mild dissatisfaction with the service, which 'could have been better'. The mixed feedback suggests a balance between positive and negative aspects, leading to an overall neutral sentiment.\",\n",
      "  \"Classification\": \"Neutral\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import SequentialChain, LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#Define lis of examples with reasoning\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"text\": \"i absolutely love this product. Exceeds expectations\",\n",
    "        \"reasoning\": \"the text expresses a lot of positive emotions and satisfaction with the product\",\n",
    "        \"classification\": \"Positive\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"The customer service was terrible, and I am very disappointed with the response time.\",\n",
    "        \"reasoning\": \"The text indicates frustration and dissatisfaction with the customer service experience.\",\n",
    "        \"classification\": \"Negative\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"The movie was okay, not the best I've seen, but not the worst either.\",\n",
    "        \"reasoning\": \"The text shows a neutral attitude, as it neither expresses strong positive nor negative emotions.\",\n",
    "        \"classification\": \"Neutral\"\n",
    "    }\n",
    "\n",
    "]\n",
    "\n",
    "#create a prompt template for each example\n",
    "example_template=\"\"\"\n",
    "\"Text\": \"{text}\",\n",
    "\"Reasoning: \"{reasoning}\",\n",
    "\"Classification\": \"{classification}\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"reasoning\", \"classification\"],\n",
    "    template= example_template\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Below are some examples that classify text with reasoning:\\n\\n\",\n",
    "    suffix=\"\\n\\nClassify the following text with reasoning:\\nText: {text}\\n\\nProvide your answer in the JSON format with Reasoning and Classification keys\",\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo\")\n",
    "\n",
    "chain_of_thought_chain =  LLMChain(llm=llm, prompt=few_shot_prompt)\n",
    "#sequential_chain= SequentialChain(chains=[chain_of_thought_chain])\n",
    "\n",
    "text_to_classify= \"The food was decent, but the service could have been better.\"\n",
    "\n",
    "\n",
    "response= chain_of_thought_chain.invoke(text_to_classify)\n",
    "response_text = response[\"text\"]\n",
    "print(response_text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Reasoning: The text presents a mixed sentiment where it criticizes one aspect of the experience (\"The service was slow\") while praising another (\"the food was absolutely amazing\"). The use of the word \"absolutely\" with \"amazing\" to describe the food suggests a strong positive feeling that outweighs the negative aspect of slow service.\\n\\nClassification: Positive' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 137, 'total_tokens': 207, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_83975a045a', 'finish_reason': 'stop', 'logprobs': None} id='run-46e8f4bd-d4c0-4d29-8252-f6f98f2cdd96-0' usage_metadata={'input_tokens': 137, 'output_tokens': 70, 'total_tokens': 207, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n",
      "Reasoning: The text presents a mixed sentiment where it criticizes one aspect of the experience (\"The service was slow\") while praising another (\"the food was absolutely amazing\"). The use of the word \"absolutely\" with \"amazing\" to describe the food suggests a strong positive feeling that outweighs the negative aspect of slow service.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate, PipelinePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Step 1: Define a template to generate reasoning for the classification\n",
    "reasoning_template = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=\"Analyze the following text and provide reasoning for its sentiment classification in the following format:\\n\"\n",
    "             \"Reasoning: <Provide reasoning here>\\n\"\n",
    "             \"Text: {text}\\nReasoning:\"\n",
    ")\n",
    "\n",
    "# Step 2: Define a template that uses the reasoning to classify the sentiment\n",
    "classification_template = PromptTemplate(\n",
    "    input_variables=[\"reasoning\"],\n",
    "    template=\"Based on the reasoning provided below, classify the sentiment as Positive, Negative, or Neutral in the following format:\\n\"\n",
    "             \"Classification: <Provide classification here>\\n\"\n",
    "             \"Reasoning: {reasoning}\\nClassification:\")\n",
    "\n",
    "# Define the final prompt template that combines the outputs from both steps\n",
    "final_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"reasoning\", \"classification\"],\n",
    "    template=\"\"\"Here is the sentiment analysis result:\n",
    "Reasoning: {reasoning}\n",
    "Classification: {classification}\"\"\"\n",
    ")\n",
    "\n",
    "# Create a PipelinePromptTemplate that connects the two steps and includes the final prompt\n",
    "pipeline_template = PipelinePromptTemplate(\n",
    "    pipeline_prompts=[\n",
    "        (\"reasoning\", reasoning_template),\n",
    "        (\"classification\", classification_template)\n",
    "    ],\n",
    "    final_prompt=final_prompt_template\n",
    ")\n",
    "\n",
    "# Provide a new text to classify\n",
    "input_text = {\"text\": \"The service was slow, but the food was absolutely amazing.\"}\n",
    "\n",
    "# Run the pipeline\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo\")\n",
    "response = llm(pipeline_template.format(**input_text))\n",
    "\n",
    "print(response)\n",
    "\n",
    "reasoning_start = response.content.find(\"Reasoning: \") + len(\"Reasoning: \")\n",
    "reasoning_end = response.content.find(\"Classification: \") - 1\n",
    "reasoning = response.content[reasoning_start:reasoning_end].strip()\n",
    "\n",
    "classification_start = response.content.find(\"Classification: \") + len(\"Classification: \")\n",
    "classification = response.content[classification_start:].strip()\n",
    "\n",
    "# Print the output\n",
    "print(f\"Reasoning: {reasoning}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text \"Movie had no plot, but the action kept us on our toes!\" expresses a mixed sentiment. On one hand, the statement \"Movie had no plot\" conveys a negative opinion about the movie, suggesting a lack of a cohesive or engaging storyline which is generally considered a critical aspect of good filmmaking. This part of the text indicates dissatisfaction or disappointment.\n",
      "\n",
      "On the other hand, the phrase \"but the action kept us on our toes!\" introduces a contrasting positive sentiment. It suggests that despite the absence of a strong plot, the action sequences in the movie were exciting and engaging, enough to maintain the viewer's interest and keep them alert and anxious in a positive way. The use of the expression \"kept us on our toes\" typically means that the action was thrilling and possibly suspenseful, contributing positively to the viewer's experience.\n",
      "\n",
      "Overall, the sentiment analysis of this text would identify a balance of negative and positive sentiments. The negative sentiment about the lack of plot is somewhat mitigated by the positive response to the action scenes, resulting in an overall mixed sentiment about the movie.\n",
      "Classification: Neutral\n",
      "Here is the complete  analysis:\n",
      "\n",
      "Reasoning: The text \"Movie had no plot, but the action kept us on our toes!\" expresses a mixed sentiment. On one hand, the statement \"Movie had no plot\" conveys a negative opinion about the movie, suggesting a lack of a cohesive or engaging storyline which is generally considered a critical aspect of good filmmaking. This part of the text indicates dissatisfaction or disappointment.\n",
      "\n",
      "On the other hand, the phrase \"but the action kept us on our toes!\" introduces a contrasting positive sentiment. It suggests that despite the absence of a strong plot, the action sequences in the movie were exciting and engaging, enough to maintain the viewer's interest and keep them alert and anxious in a positive way. The use of the expression \"kept us on our toes\" typically means that the action was thrilling and possibly suspenseful, contributing positively to the viewer's experience.\n",
      "\n",
      "Overall, the sentiment analysis of this text would identify a balance of negative and positive sentiments. The negative sentiment about the lack of plot is somewhat mitigated by the positive response to the action scenes, resulting in an overall mixed sentiment about the movie.\n",
      "\n",
      "Classification: Classification: Neutral\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "reasoning_template = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=\"The sentiment analysis reasoning for the text is as follows:\\nText: {text}\\nReasoning: <explain here>\"\n",
    ")\n",
    "\n",
    "classification_template = PromptTemplate(\n",
    "    input_variables=[\"reasoning\"],\n",
    "    template=\"Based on the reasoning provided, classify the sentiment as Positive, Negative, or Neutral.\\nReasoning: {reasoning}\\nClassification: <classification here>\"\n",
    ")\n",
    "\n",
    "final_template = PromptTemplate(\n",
    "    input_variables=[\"reasoning\", \"classification\"],\n",
    "    template=\"Here is the complete  analysis:\\n\\nReasoning: {reasoning}\\n\\nClassification: {classification}\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo\")\n",
    "\n",
    "reasoning_chain = LLMChain(llm=llm, prompt=reasoning_template)\n",
    "classification_chain = LLMChain(llm=llm, prompt=classification_template)\n",
    "\n",
    "# Run the reasoning chain to generate reasoning\n",
    "reasoning_output = reasoning_chain.run({\"text\": \"Movie had no plot, but the action kept us on our toes!\"})\n",
    "print(reasoning_output)\n",
    "# Run the classification chain to generate classification based on the reasoning\n",
    "classification_output = classification_chain.run({\"reasoning\": reasoning_output})\n",
    "print(classification_output)\n",
    "# Format the final template with the generated reasoning and classification\n",
    "final_prompt = final_template.format(reasoning=reasoning_output, classification=classification_output)\n",
    "\n",
    "# Print the final output\n",
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
