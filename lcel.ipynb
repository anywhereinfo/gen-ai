{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the pirate bring a fish to the poker game?\\n\\nBecause he heard they were playing for goldfish! Arrr, trying to plunder the sea one scale at a time!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate, ChatMessagePromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "system_template = ChatMessagePromptTemplate.from_template(\n",
    "    \"You are a comedian specialized in {style} humor.\",\n",
    "    role=\"system\"\n",
    ")\n",
    "\n",
    "message_template= ChatMessagePromptTemplate.from_template(\n",
    "     template=\"tell a joke about: {topic}\",\n",
    "     role=\"user\"\n",
    ")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_template, message_template])\n",
    "model = ChatOpenAI(model=\"gpt-4-turbo\", temperature=1)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = chat_prompt | model | output_parser\n",
    "input = {\n",
    "    \"style\" : \"pirate commedian\",\n",
    "    \"topic\" : \"fish\"\n",
    "}\n",
    "\n",
    "chain.invoke(input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AddTen: 10\n",
      "Multiply by 2: 20\n",
      "Convert to string: 40\n",
      "Result: 40\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import TypeVar, Generic\n",
    "\n",
    "T = TypeVar('T')\n",
    "U = TypeVar('U')\n",
    "\n",
    "class CRunnable(ABC, Generic[T, U]):\n",
    "    @abstractmethod\n",
    "    def invoke(self, data: T) -> U:\n",
    "        \"\"\"Abstract method that must be implemented by subclasses\"\"\"\n",
    "\n",
    "class Chain(CRunnable):\n",
    "    def __init__(self, first: CRunnable, second: CRunnable):\n",
    "        self.first = first\n",
    "        self.second = second\n",
    "\n",
    "    def invoke(self, data):\n",
    "        first_result = self.first.invoke(data)\n",
    "        return self.second.invoke(first_result)\n",
    "\n",
    "class Pipe:\n",
    "    def __init__(self, runnable: CRunnable):\n",
    "        self._runnable = runnable\n",
    "    \n",
    "    def __or__(self, other: 'Pipe') -> 'Pipe':\n",
    "        # other is a Pipe, so we need to access its _runnable\n",
    "        # Create a Chain with both wrapped CRunnables\n",
    "        chained = Chain(self._runnable, other._runnable)\n",
    "        # Wrap the chain in a new Pipe\n",
    "        return Pipe(chained)\n",
    "    \n",
    "    def invoke(self, data):\n",
    "        return self._runnable.invoke(data)\n",
    "\n",
    "class AddTen(CRunnable):\n",
    "    def invoke(self, data: int) -> int:\n",
    "        print(\"AddTen:\", data)\n",
    "        return data + 10\n",
    "\n",
    "class MultiplyByTwo(CRunnable):\n",
    "    def invoke(self, data: int) -> int:\n",
    "        print(\"Multiply by 2:\", data)\n",
    "        return data * 2\n",
    "\n",
    "class ConvertToString(CRunnable):\n",
    "    def invoke(self, data: int) -> str:\n",
    "        print(\"Convert to string:\", data)\n",
    "        return f\"Result: {data}\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Each CRunnable is wrapped in a Pipe\n",
    "    a = Pipe(AddTen())\n",
    "    b = Pipe(MultiplyByTwo())\n",
    "    c = Pipe(ConvertToString())\n",
    "\n",
    "    chain = a | b | c  # Now pipe operators work on Pipe objects\n",
    "    result = chain.invoke(10)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain started with metadata: {'user_id': 'user123', 'request_id': 'req456', 'session_start': '2024-03-06T10:00:00', 'query_type': 'analysis', 'priority': 'high'}\n",
      "User ID: user123\n",
      "Request ID: req456\n",
      "Chain started with metadata: {'user_id': 'user123', 'request_id': 'req456', 'session_start': '2024-03-06T10:00:00', 'query_type': 'analysis', 'priority': 'high'}\n",
      "User ID: user123\n",
      "Request ID: req456\n",
      "Chain completed for request: None\n",
      "Chain started with metadata: {'user_id': 'user123', 'request_id': 'req456', 'session_start': '2024-03-06T10:00:00', 'query_type': 'analysis', 'priority': 'high'}\n",
      "User ID: user123\n",
      "Request ID: req456\n",
      "Chain completed for request: None\n",
      "Chain completed for request: None\n",
      "Chain started with metadata: {'department': 'Research', 'cost_center': 'ML-Team', 'project_code': 'AI-2024', 'billing_type': 'internal'}\n",
      "User ID: None\n",
      "Request ID: None\n",
      "Chain started with metadata: {'department': 'Research', 'cost_center': 'ML-Team', 'project_code': 'AI-2024', 'billing_type': 'internal'}\n",
      "User ID: None\n",
      "Request ID: None\n",
      "Chain completed for request: None\n",
      "Chain completed for request: None\n",
      "Chain started with metadata: {'debug_level': 'verbose', 'trace_id': 'trace-123', 'component_version': 'v1.2.3', 'environment': 'development'}\n",
      "User ID: None\n",
      "Request ID: None\n",
      "Chain started with metadata: {'debug_level': 'verbose', 'trace_id': 'trace-123', 'component_version': 'v1.2.3', 'environment': 'development'}\n",
      "User ID: None\n",
      "Request ID: None\n",
      "Chain completed for request: None\n",
      "Chain completed for request: None\n",
      "Chain started with metadata: {'test_id': 'ab_test_001', 'variant': 'B', 'test_group': 'experimental', 'feature_flags': {'new_model': True}}\n",
      "User ID: None\n",
      "Request ID: None\n",
      "Chain started with metadata: {'test_id': 'ab_test_001', 'variant': 'B', 'test_group': 'experimental', 'feature_flags': {'new_model': True}}\n",
      "User ID: None\n",
      "Request ID: None\n",
      "Chain completed for request: None\n",
      "Chain completed for request: None\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain.schema.runnable import RunnableConfig\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain_core.tracers.stdout import ConsoleCallbackHandler\n",
    "\n",
    "# Custom callback handler to demonstrate metadata usage\n",
    "class MetadataTracker(BaseCallbackHandler):\n",
    "    def on_chain_start(self, serialized, inputs, **kwargs):\n",
    "        # Access metadata from the config\n",
    "        metadata = kwargs.get(\"metadata\", {})\n",
    "        print(f\"Chain started with metadata: {metadata}\")\n",
    "        print(f\"User ID: {metadata.get('user_id')}\")\n",
    "        print(f\"Request ID: {metadata.get('request_id')}\")\n",
    "\n",
    "    def on_chain_end(self, outputs, **kwargs):\n",
    "        metadata = kwargs.get(\"metadata\", {})\n",
    "        print(f\"Chain completed for request: {metadata.get('request_id')}\")\n",
    "\n",
    "# Initialize components\n",
    "model = ChatOpenAI()\n",
    "metadata_tracker = MetadataTracker()\n",
    "\n",
    "# Example 1: Tracking User Sessions\n",
    "def process_user_request(user_id: str, request_id: str, query: str):\n",
    "    config = RunnableConfig(\n",
    "        metadata={\n",
    "            \"user_id\": user_id,\n",
    "            \"request_id\": request_id,\n",
    "            \"session_start\": \"2024-03-06T10:00:00\",\n",
    "            \"query_type\": \"analysis\",\n",
    "            \"priority\": \"high\"\n",
    "        },\n",
    "        callbacks=[metadata_tracker]\n",
    "    )\n",
    "\n",
    "    parallel_chain = RunnableParallel({\n",
    "        \"analysis\": lambda x: \"Analysis result\",\n",
    "        \"summary\": lambda x: \"Summary result\"\n",
    "    })\n",
    "\n",
    "    return parallel_chain.invoke({\"query\": query}, config=config)\n",
    "\n",
    "# Example 2: Cost Tracking\n",
    "def process_with_cost_tracking(query: str, department: str):\n",
    "    config = RunnableConfig(\n",
    "        metadata={\n",
    "            \"department\": department,\n",
    "            \"cost_center\": \"ML-Team\",\n",
    "            \"project_code\": \"AI-2024\",\n",
    "            \"billing_type\": \"internal\"\n",
    "        },\n",
    "        callbacks=[metadata_tracker]\n",
    "    )\n",
    "    \n",
    "    chain = RunnableParallel({\n",
    "        \"result\": lambda x: \"Processing result\"\n",
    "    })\n",
    "    \n",
    "    return chain.invoke({\"query\": query}, config=config)\n",
    "\n",
    "# Example 3: Debugging and Tracing\n",
    "def debug_chain_execution(query: str):\n",
    "    config = RunnableConfig(\n",
    "        metadata={\n",
    "            \"debug_level\": \"verbose\",\n",
    "            \"trace_id\": \"trace-123\",\n",
    "            \"component_version\": \"v1.2.3\",\n",
    "            \"environment\": \"development\"\n",
    "        },\n",
    "        callbacks=[metadata_tracker]\n",
    "    )\n",
    "    \n",
    "    chain = RunnableParallel({\n",
    "        \"result\": lambda x: \"Debug result\"\n",
    "    })\n",
    "    \n",
    "    return chain.invoke({\"query\": query}, config=config)\n",
    "\n",
    "# Example 4: A/B Testing\n",
    "def ab_test_chain(query: str, test_variant: str):\n",
    "    config = RunnableConfig(\n",
    "        metadata={\n",
    "            \"test_id\": \"ab_test_001\",\n",
    "            \"variant\": test_variant,\n",
    "            \"test_group\": \"experimental\",\n",
    "            \"feature_flags\": {\"new_model\": True}\n",
    "        },\n",
    "        callbacks=[metadata_tracker]\n",
    "    )\n",
    "    \n",
    "    chain = RunnableParallel({\n",
    "        \"result\": lambda x: f\"Result for variant {test_variant}\"\n",
    "    })\n",
    "    \n",
    "    return chain.invoke({\"query\": query}, config=config)\n",
    "\n",
    "# Usage examples\n",
    "if __name__ == \"__main__\":\n",
    "    # Track user session\n",
    "    result1 = process_user_request(\n",
    "        user_id=\"user123\",\n",
    "        request_id=\"req456\",\n",
    "        query=\"analyze this\"\n",
    "    )\n",
    "\n",
    "    # Track costs\n",
    "    result2 = process_with_cost_tracking(\n",
    "        query=\"process this\",\n",
    "        department=\"Research\"\n",
    "    )\n",
    "\n",
    "    # Debug execution\n",
    "    result3 = debug_chain_execution(\n",
    "        query=\"debug this\"\n",
    "    )\n",
    "\n",
    "    # A/B testing\n",
    "    result4 = ab_test_chain(\n",
    "        query=\"test this\",\n",
    "        test_variant=\"B\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: Hello\n",
      "word: world\n",
      "word: how\n",
      "word: are\n",
      "word: you\n",
      "Helloworldhowareyou\n"
     ]
    }
   ],
   "source": [
    "from typing import Iterator\n",
    "from langchain_core.runnables import RunnableGenerator\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def word_by_word(input_stream: Iterator) -> Iterator[str]:\n",
    "    for chunk in input_stream:\n",
    "        text = str(chunk)\n",
    "        for word in text.split():\n",
    "            print(f\"Yielding: {word}\")  # Let's see what's being yielded\n",
    "            yield word\n",
    "\n",
    "word_streamer = RunnableGenerator(word_by_word)\n",
    "\n",
    "# Method 1: Using invoke (consumes all yields and joins them)\n",
    "result = word_streamer.invoke(\"Hello world\")\n",
    "print(\"invoke result:\", result)\n",
    "\n",
    "# Method 2: Using stream (gets iterator)\n",
    "for word in word_streamer.stream(\"Hello world\"):\n",
    "    print(\"stream word:\", word)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
